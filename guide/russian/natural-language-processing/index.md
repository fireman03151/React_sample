---
title: Introduction to NLP
localeTitle: Введение в НЛП
---
## Контур

*   мотивация
*   Случаи применения
*   Языковое моделирование
*   Дальнейшие чтения

## мотивация

Мы всегда мечтали, чтобы машины поняли наш язык. С тех пор, как Хомский придумал бесплатные грамматики контекста, лингвисты хотели придумать решения для понимания контекстно-зависимых грамматик. Поэтому естественно, что академический ученик развился вокруг этой темы.

## Случаи применения

Люди использовали эту концепцию во множестве интересных приложений. Немногие из интересных включают Google Translate, Siri или Gmail ответы автоответ. Тем не менее, люди работают над тем, как улучшить эти прогнозы, и ведутся современные исследования в отношении того, как заставить машины отвечать на вопросы более надежно.

## Как работает обработка естественного языка

Ранее НЛП применял подход, основанный на правилах, т. Е. Все правила были жестко закодированы (например, грамматика написания). Однако это не сильно повлияло на вариации в языковых моделях. В настоящее время процессы НЛП осуществляются с использованием искусственного интеллекта. Они полагаются главным образом на Deep Learning, AI, который определяет шаблоны в данных и использует их для обучения модели. Этот метод лучше, чем используемые ранее методы, потому что, изучая огромные данные, машина может сфокусироваться на большинстве распространенных случаев, что нелегко с помощью рукописных правил, потому что не является очевидным, где должны быть предприняты усилия , Кроме того, эти модели становятся более надежными с увеличением объема данных, но в более ранних подходах это делается только путем повышения сложности правил, что является более сложной задачей. Модель изучает правила языка посредством анализа больших корпусов типичных примеров реального мира. Этот метод требует огромного количества помеченных данных, что является большим препятствием для НЛП.

## Языковое моделирование

Для тех, кто хочет попасть в эту область, я намерен начать с 2 концепций.

#### токенизации

Здесь задача звучит просто. Учитывая корпус (набор предложений), генерируйте отдельные токены (значащие слова). Нам нужно обозначить слова и предложения. Первый подход, который приходит на ум, состоит в том, чтобы разделить на период и пространство. Это, однако, не работает. Подумайте, мистер Джон. Являются ли предложения «г-н» и «Иоанн» 2? Конечно нет. Теперь рассмотрим дефис разделенные слова. Вы хотите разбить их на 2 слова или на одно слово? Эти сложные вопросы делают задачу токенизации не столь простой. Идем дальше и выбираем корпус из nltk и создаем собственное регулярное выражение для вашего собственного токенизатора!

#### n-граммовые модели

Следующей задачей является создание языковой модели. Здесь мы рассмотрим предположение, что n-е слово зависит только от предыдущих n-1 слов. Наиболее часто используются 2-граммовые и 3-граммовые модели. Чтобы построить 3-граммовую модель, просто объедините 3 жетона и подсчитайте их частоту в корпусе. Теперь вы готовы предсказать вероятность группы из трех слов!

## Дальнейшие чтения

Область НЛП огромна. Если вы прочитали это далеко и выполнили вышеизложенное, вам это, безусловно, понравилось. Продолжайте читать книгу Юрафского, чтобы узнать еще несколько новых концепций. Помните, что важно их реализовать.