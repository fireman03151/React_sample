---
title: Overfitting Has Many Faces
localeTitle: التجهيز له العديد من الوجوه
---
## التجهيز له العديد من الوجوه

إذا كانت خوارزمية التعلم تناسب مجموعة تدريب معينة ، فهذا لا يشير ببساطة إلى فرضية جيدة. يحدث overfitting عندما تناسب وظيفة فرضية J (Θ) مجموعة التدريب الخاصة بك عن كثب وجود تباين عال وخطأ منخفض في مجموعة التدريب مع وجود خطأ اختبار عالي على أي بيانات أخرى.

بمعنى آخر ، قم بتغطية الحروف الناقصة إذا كان خطأ الفرضية كما تم قياسه على مجموعة البيانات التي تم استخدامها لتدريب المعلمات يحدث أقل من الخطأ في أي مجموعة بيانات أخرى.

### اختيار درجة متعددة الحدود الأمثل

إن اختيار الدرجة المناسبة من كثير الحدود لوظيفة الافتراض مهم في تجنب التكرار. ويمكن تحقيق ذلك من خلال اختبار كل درجة متعددة الحدود وملاحظة التأثير على نتيجة الخطأ عبر أجزاء مختلفة من مجموعة البيانات. ومن ثم ، يمكننا تقسيم مجموعة البيانات الخاصة بنا إلى 3 أجزاء يمكن استخدامها في تحسين فرضية "ثيتا" و "درجة متعددة الحدود".

نسبة الاختصار الجيد لمجموعة البيانات هي:

*   مجموعة التدريب: 60 ٪
*   التصديق المتقاطع: 20٪
*   مجموعة الاختبار: 20 ٪

وبالتالي يمكن حساب قيم الخطأ الثلاثة بالطريقة التالية: 1

1.  استخدام مجموعة التدريب لكل درجة متعددة الحدود من أجل تحسين المعلمات في `Θ`
2.  استخدم مجموعة التحقق من الصحة المتقاطعة للعثور على درجة متعددة الحدود مع أدنى خطأ
3.  استخدم مجموعة الاختبار لتقدير خطأ التعميم

### طرق لإصلاح التثبيت

هذه بعض طرق معالجة التجهيز:

1.  الحصول على المزيد من الأمثلة التدريبية
2.  جرب مجموعة أصغر من الميزات
3.  زيادة المعلمة `λ lambda`

#### معلومات اكثر:

[دورة تعلم الآلة في كورسيرا](https://www.coursera.org/learn/machine-learning)

### مصادر

1.  [نج ، أندرو. "تعلم الآلة". _Corsera_ الوصول إليها في 29 يناير 2018](https://www.coursera.org/learn/machine-learning)