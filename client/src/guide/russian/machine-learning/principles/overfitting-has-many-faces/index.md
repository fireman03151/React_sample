---
title: Overfitting Has Many Faces
localeTitle: Переопределение имеет много лиц
---
## Переопределение имеет много лиц

Если алгоритм обучения хорошо подходит для данного тренировочного набора, это не просто указывает на хорошую гипотезу. Переполнение происходит, когда функция гипотезы J (Θ) слишком точно соответствует вашему набору тренировок с высокой дисперсией и низкой ошибкой в ​​наборе тренировок при наличии высокой тестовой ошибки для любых других данных.

Другими словами, overfitting occrus, если ошибка гипотезы, измеренная в наборе данных, которая использовалась для обучения параметров, оказалась ниже ошибки в любом другом наборе данных.

### Выбор оптимальной полиномиальной степени

Выбор правильной степени полинома для функции гипотезы важен для предотвращения переобучения. Это может быть достигнуто путем тестирования каждой степени полинома и наблюдения эффекта на результат ошибки в различных частях набора данных. Следовательно, мы можем разбить наш набор данных на 3 части, которые можно использовать для оптимизации гипотезы «тета и полиномиальная степень».

Хорошим коэффициентом разложения набора данных является:

*   Учебный комплект: 60%
*   Перекрестная проверка: 20%
*   Испытательный набор: 20%

Таким образом, три значения ошибки могут быть вычислены по следующему методу: 1

1.  Используйте набор тренировок для каждой степени полинома, чтобы оптимизировать параметры в `Θ`
2.  Используйте набор перекрестной проверки, чтобы найти степень полинома с наименьшей ошибкой
3.  Используйте тестовый набор для оценки ошибки обобщения

### Способы исправления переполнения

Вот некоторые из способов решения проблемы переобучения:

1.  Получение дополнительных примеров обучения
2.  Попытка меньшего набора функций
3.  Увеличение параметра `λ lambda`

#### Дополнительная информация:

[Курсы машинного обучения Курсеры](https://www.coursera.org/learn/machine-learning)

### источники

1.  [Эндрю. "Машинное обучение". _Доступна Coursera_ 29 января 2018 года](https://www.coursera.org/learn/machine-learning)