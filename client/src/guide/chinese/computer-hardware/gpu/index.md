---
title: GPU
localeTitle: GPU
---
## GPU

GPU代表图形处理单元。大多数计算机使用这些来渲染视频或玩视频游戏。

GPU就像CPU，但具有不同的优点和缺点。 CPU非常擅长快速运行几项任务。 GPU在同时运行许多任务方面要好得多，但速度较慢。典型的GPU可以运行超过10,000个任务，但是要同时运行这么多任务，它们必须共享内存和其他资源。 GPU通常会反复运行非常重复的任务，以免CPU浪费时间。有些CPU具有内置GPU，但拥有单独的GPU几乎总是更强大。

GPU可用于计算以及视频渲染。常见的方法包括OpenACC，CUDA，OpenCL和OpenGL。一些应用程序包括GPU实现，以减少应用程序运行所需的时间。

GPU最初主要用于3D游戏渲染，以提高分辨率和帧率。但是现在更广泛地利用这些功能来改善许多领域的计算工作量;例如财务建模，尖端科学研究和石油和天然气勘探。 GPU也被用作比特币挖掘的资源，因为它们能够轻松地运行重复任务而不会占用CPU的资源，这允许您在具有低端CPU的计算机上运行操作系统，同时仍然可以使用比特币使用GPU

有两个主要品牌生产GPU：NVidia和AMD。他们通常被称为“绿色团队”和“红色团队”，表明他们的标志的主要颜色。

着名的GPU制造商包括：Nvidia和AMD / ATI。

## GPU的起源

GPU的大多数原始背景可以映射到VGA（虚拟图形阵列）控制器的时代。但这些实际上并不是一个整体处理单元，而是充当显示功能的支持单元。 VGA控制器是连接到动态RAM和显示发生器的简单存储器控制器。 VGA的主要功能是接收图像数据，正确排列并将其发送到视频设备，视频设备主要是计算机监视器或连接到游戏控制台进行显示的电视屏幕。

第一个成熟的图形加速处理单元由NVIDIA于1999年开发并销售，“GeForce 256”。较旧的3D加速器必须依靠CPU来执行图形计算。新的“GeForce 256”作为CPU的协处理器，将帧速率提高了50％以上并降低了总成本，从而在消费市场中扩展自己。

## GPU与CPU

CPU针对最小延迟进行了优化，即“在给定的时间窗口内能够执行尽可能多的属于单个串行线程的指令”。处理器必须能够在操作之间快速切换。为了在CPU上获得大量延迟，CPU中有许多基础设施，比如大型缓存可以随时执行数据，大量的无序执行控制单元以及一些ALU内核。 CPU的ISA以更通用的方式设计，并且可以执行广泛的操作。 虽然CPU是为通用计算和指令而设计的，但GPU是为图形计算而发展的。对于图形的2D / 3D渲染，需要对数百和数千个像素执行相同的计算。因此，GPU主要针对最大吞吐量进行了优化。这是在单一架构中使用大量ALU实现的。 L2缓存缩小，因为在从DRAM获取数据之前，GPU核心需要执行大量计算，从而将CPU停顿时间与大量并行性重叠。这称为延迟隐藏。

## GPU架构的演变

GPU最初是以图形管道的概念为蓝本的。图形管道是一个理论模型，包括如何使用GPU和软件（如OpenGL，DirectX）发送和执行图形数据的级别。管道基本上将3D空间坐标转换为2D像素化数据以供设备显示。以下是“传统固定功能图形管道”的说明，这是迄今为止普遍接受的管道。

### 第0代

Silicon Graphics Inc.（SGI）的“Reality Engine”板标志着GPU硬件和图形管道的出现。但该技术仍然依赖于上半年的CPU。此外，速度限制为每个时钟周期执行一个像素。该引擎使用OpenGL，一种广泛使用的2D / 3D应用程序编程。

### 1stGeneration

“3dfx Voodoo”（1996）演变为第一款真正的3D游戏加速器之一。它处理纹理映射，光栅化和z缓冲，但CPU仍然必须进行顶点转换。

### 2ndGeneration

这是第一款真正的GPU，即NVIDIA的“GeForce 256”在共同市场上发布的时刻。这一代的GPU使用了加速图形端口（AGP），提供了多种纹理，硬件几何变换，光照贴图和照明等新功能。传统的管道被称为“固定功能”管道，因为一旦开发人员将图形数据发送到GPU的管道，数据就无法更改。

### 第三代

通过这一代CPU，可编程流水线技术应运而生。现在，以前的不可编程部件可以由程序员编程。 2001年，NVIDIA发布了GeForce3。

### 第四代

随着21世纪初，第一个“完全可编程显卡”已经达到了消费者的目的。 NVIDIA GeForce FX，ATI Radeon 9700是第一款。这些GPU可以执行逐像素操作以及像素着色器和可编程顶点。但是，顶点着色器和像素着色器处理需要单独的专用硬件。

### 第五代

GPU正在不断发展并以其最高速率发展，而这一代GPU是第一批使用PCI-express总线的GPU。引入了多个渲染缓冲区，64位支持，纹理访问等，以及GPU内存的增加。

### 第六代

2006年，NVIDIA GeForce 8系列GPU的发布，通过将GPU作为大规模并行处理器引入，彻底改变了GPU产业和范围。它是第一个拥有“统一”和“可编程”着色器，或者换句话说，可编程统一处理器。统一意味着图形管道的所有过程都在一个处理器上执行，任何阶段都不需要外部单元。下面讨论基本的Unified GPU架构组件。

自9XX系列NVidia GPU发布以来，各代之间的性能提升只会更好。从980Ti到1080Ti以及新推出的208Tis，性能提升了一倍多。 AMD也开始生产更好的GPU，如RX 580和Vega 64，尽管这仍然远不及Nvidia的水平。 就在最近，Nvidia推出了一系列名为RTX的GPU，其中包括2080Ti，2080和2070等高端显卡.RTX代表“光线追踪”，这是一种渲染技术，用于生成图像，但追踪光路在一个场景中。

## 基本的统一GPU架构组件

统一GPU架构基于许多可编程处理器的并行阵列，其中图形流水线的所有阶段，即顶点，几何，光栅化，以及像素着色器处理和同一核心上的并行计算，与早期的GPU相比。处理器阵列与固定功能处理器高度集成，用于压缩和解压缩，光栅化，光栅操作，纹理过滤，抗锯齿，视频解码和高清视频处理。

以下讨论的体系结构侧重于在许多处理器核上有效地执行许多并行线程。

### 处理器阵列

处理器阵列由许多处理核心组成。统一的GPU处理器阵列具有典型的多线程多处理器组织结构。为了执行每个线程，涉及多处理器，并且在每个GPU多处理器（也称为流处理多处理器（SM））中，有许多流处理器，排列在队列中。所有处理器都通过互连网络连接到DRAM分区。

### 多线程

如前所述，GPU针对高吞吐量和延迟隐藏进行了优化。大规模多线程缩小了DRAM的内存负载延迟。由于要完成加载或提取指令，线程处于停顿状态，处理器可以执行另一个线程。此外，由于高规模多线程，GPU支持细粒度并行图形着色器编程模型和细粒度并行计算机编程模型。

### 多处理器架构

除了SM中的多个处理器内核外，还有特殊功能单元，多线程指令单元，指令和常量高速缓存以及共享内存。此外，每个核心由大型多线程寄存器文件（RF）组成。每个流处理器核心由整数和浮点运算单元组成，它们可以一起处理大多数操作。

### SIMT

流式多处理器使用“单指令多线程（SIMT）”架构。指令在称为warps的并行线程组中执行。每个并行线程属于同一类型，并在同一程序地址处一起启动。 SIMT处理器架构与SIMD架构非常相似。在SIMT中，特定指令独立地在多个并行线程中执行，而在SIMD中，在同步组中的多个数据通道中执行相同的指令。

### 流处理器

它执行所有基本的FP操作以及算术，比较，转换和逻辑PTX指令。 特别功能单位 一些线程指令在SFU上执行，同时在SP上执行其他线程指令。

#### 更多信息：

*   [维基百科](https://en.wikipedia.org/wiki/Graphics_processing_unit)
*   [OpenACC的](https://www.openacc.org/)
*   [CUDA](https://developer.nvidia.com/cuda-zone)
*   [OpenCL的](https://www.khronos.org/opencl/)
*   [OpenGL的](https://www.opengl.org/)
*   [nVidia博客](https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/)
*   [的NVidia](https://www.nvidia.com/)
*   [AMD](http://www.amd.com/en-us/products/graphics)