---
title: Spark
localeTitle: شرارة
---
## شرارة

[Spark](http://spark.apache.org/) هو نظام حوسبة سريع وعام للبيانات الضخمة. فهو يوفر واجهات برمجة التطبيقات عالية المستوى في سكالا ، وجاوا ، وبيثون ، و R ، ومحركًا محسنًا يدعم الرسومات البيانية العامة لحساب تحليل البيانات. كما يدعم مجموعة غنية من الأدوات عالية المستوى بما في ذلك Spark SQL for SQL و DataFrames و MLlib للتعلم الآلي و GraphX ​​لمعالجة الرسوم البيانية و Spark Streaming لمعالجة التدفق.

## الميزات الأساسية

يحتوي Spark 2.0 على العديد من الميزات الجديدة:

*   مصدر بيانات CSV أصلي ، يعتمد على وحدة شرارة CSV من Databricks
*   إدارة الذاكرة خارج كومة الذاكرة المؤقتة للتخزين المؤقت والتنفيذ على حد سواء
*   دعم خلية نمط دلو
*   إحصائيات موجزة تقريبية باستخدام الرسومات ، بما في ذلك الكمية التقريبية ، مرشح بلوم ، ورسم دقيقة العد.

## كيف يتم استخدامها لعلوم البيانات

أصبحت Spark أداة قياسية في صندوق أدوات العديد من علماء البيانات. بفضل مرونة خيارات API ، يمكن لأي مبرمج العمل مع Spark بلغته المفضلة. كما لاحظت [كلوديرا](https://blog.cloudera.com/blog/2014/03/why-apache-spark-is-a-crossover-hit-for-data-scientists) ، اكتسب سبارك شعبية لعدة أسباب:

*   كونها تعتمد على Scala ، تدمج Spark في أي نظام تشغيلي قائم على JVM ، ولكن يمكن استخدامها أيضًا بشكل تفاعلي في REPL بطريقة ستشعر مألوفًا لدى مستخدمي R و Python.
*   بالنسبة لمبرمجين Java ، لا تزال Scala تقدم منحنى تعلم. ولكن على الأقل ، يمكن استخدام أي مكتبة Java من داخل Scala. يشبه تجريد (RDD) (مجموعة البيانات الموزعة المرنة) من Spark PCollection من Crunch ، والذي أثبت أنه تجريد مفيد في Hadoop سيكون مألوفًا بالفعل لمطوري Crunch. (حتى يمكن استخدام أزمة أعلى سبارك.)
*   سبارك يقلد واجهة برمجة تطبيقات مجموعات سكالا والأسلوب الوظيفي ، وهو نعمة لمطوّري جافا وسكالا ، ولكن أيضًا مألوفًا للمطورين القادمين من بايثون. سكالا هو أيضا خيار مقنع للحوسبة الإحصائية.
*   سبارك نفسها ، و Scala تحتها ، ليست خاصة بالتعلم الآلي. أنها توفر واجهات برمجة التطبيقات دعم المهام ذات الصلة ، مثل الوصول إلى البيانات ، ETL ، والتكامل. كما هو الحال مع بايثون ، يمكن تنفيذ خط أنابيب علوم البيانات بأكمله ضمن هذا النموذج ، وليس فقط تركيب النموذج وتحليله.
*   يمكن استخدام التعليمات البرمجية التي يتم تنفيذها في بيئة REPL معظمها كما هو في سياق التشغيل.
*   يتم توزيع عمليات البيانات بشفافية عبر المجموعة ، حتى أثناء الكتابة.

#### معلومات اكثر

*   [سبارك جيثب الصفحة](https://github.com/apache/spark)
*   [ويكيبيديا](https://en.wikipedia.org/wiki/Apache_Spark)